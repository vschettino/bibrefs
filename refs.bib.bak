% Encoding: UTF-8


@InProceedings{Ackerman1984,
  Title                    = {Software Inspections and the Industrial Production of Software},
  Author                   = {Ackerman, A. Frank and Fowler, Priscilla J. and Ebenau, Robert G.},
  Booktitle                = {Proc. Of a Symposium on Software Validation: Inspection-testing-verification-alternatives},
  Year                     = {1984},
  Pages                    = {13--40},

  ISBN                     = {0-444-87593-X},
  Location                 = {Darmstadt, Germany},
  Numpages                 = {28}
}

@Conference{Aman201337,
  Title                    = {0-1 programming model-based method for planning code review using bug fix history},
  Author                   = {Aman, H.},
  Year                     = {2013},
  Pages                    = {37-42},
  Volume                   = {2},

  Abstract                 = {Code review is a powerful activity for software quality improvement, and is ideal to review all source files being developed. However, such an exhaustive review would be difficult because the available time and effort are in reality limited. Thus, practitioners prioritize the source files in terms of bug-proneness by using related data such as bug fix history, and review them in decreasing order of priority - such strategy in this paper is called the "conventional method." While the conventional method is straightforward, it focuses only on the bug-proneness and cannot consider the review cost properly, so the method does not produce a cost-effective review plan. To take into account both the bug-proneness and the review cost, this paper proposes a 0-1 programming model-based method for planning code review. The proposed method formulates a review plan as a 0-1 programming problem, and the solution is the recommendation list of source files to be reviewed. Moreover, the proposed method considers the type of file - if the file is newly-developed or not. Such difference in file type may affect on how to evaluate the bug-proneness and the review strategy: newly-developed files are notable but not appeared in the bug fix history. This paper conducts a case study using popular open source software, shows that the proposed method is up to 42% more effective than the conventional method in recommending buggy files as the review targets. {\copyright} 2013 IEEE.},
  Affiliation              = {Center for Information Technology, Ehime University, Matsuyama, Japan},
  Art_number               = {6754348},
  Author_keywords          = {0-1 programming model; Bug fix history; Code review; Cost-effectiveness},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/APSEC.2013.109},
  Journal                  = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
  Source                   = {Scopus}
}

@InProceedings{araujo2006,
  Title                    = {Métodos Estatísticos aplicados em Engenharia de Software Experimental},
  Author                   = {Marco Antônio Pereira Araújo and Márcio de Oliveira Barros and Guilherme Horta Travassos and Leonardo Gresta Paulino Murta},
  Booktitle                = {ANAIS do XX SBBD},
  Year                     = {2006},
  Editor                   = {XX Simpósio Brasileiro de Engenharia de Software},
  Organization             = {SBBD},
  Pages                    = {325}
}

@InProceedings{4076712,
  Title                    = {Patch Review Processes in Open Source Software Development Communities: A Comparative Case Study},
  Author                   = {Asundi, J. and Jayant, R.},
  Booktitle                = {System Sciences, 2007. HICSS 2007. 40th Annual Hawaii International Conference on},
  Year                     = {2007},
  Pages                    = {166c-166c},

  Abstract                 = {In spite of the overwhelming success of free/open source software (F/OSS) like Apache and GNU/Linux, there is a limited understanding of the processes and methodologies that specify this form of software development. In this paper, we examine the process of patch reviews as a proxy for the extent of code-review in F/OSS projects. While existing descriptions of patch review processes are mostly narrative and based on individual experiences, we systematically analyze the email archives of five F/OSS projects to characterize this process. While doing so, we make a distinction between contributions (patches or review comments) by core members and casual contributors to grasp the role of core members in this process. Our results show that while the patch review processes are not exactly identical across various F/OSS projects, the core members across all projects play the vital role of gate-keepers to ensure a high level of review for submitted patches},
  Doi                      = {10.1109/HICSS.2007.426},
  ISSN                     = {1530-1605}
}

@Article{Aurum2002,
  Title                    = {State-of-the-art: software inspections after 25 years.},
  Author                   = {Aurum, Aybuke and Petersson, Haakan and Wohlin, Claes},
  Journal                  = {Softw. Test., Verif. Reliab.},
  Year                     = {2002},
  Number                   = {3},
  Pages                    = {133-154},
  Volume                   = {12},

  Added-at                 = {2012-04-14T00:00:00.000+0200},
  Biburl                   = {http://www.bibsonomy.org/bibtex/23bf2dee84987cfa87e43f0ae9372d79e/dblp},
  Doi                      = {10.1002/stvr.243},
  Interhash                = {b8a61bf22fc82482905b52a64a675d91},
  Intrahash                = {3bf2dee84987cfa87e43f0ae9372d79e}
}

@InProceedings{Bacchelli2013,
  Title                    = {Expectations, Outcomes, and Challenges of Modern Code Review},
  Author                   = {Bacchelli, Alberto and Bird, Christian},
  Booktitle                = {Proceedings of the 2013 International Conference on Software Engineering},
  Year                     = {2013},
  Pages                    = {712-721},
  Publisher                = {IEEE Press},
  Series                   = {ICSE '13},

  Acmid                    = {2486882},
  ISBN                     = {978-1-4673-3076-3},
  Location                 = {San Francisco, CA, USA},
  Numpages                 = {10}
}

@Article{Basili1984,
  Title                    = {A Methodology for Collecting Valid Software Engineering Data},
  Author                   = {Basili, V. R and Weiss, D. M.},
  Journal                  = {IEEE Trans. Softw. Eng},
  Year                     = {1984},
  Pages                    = {728-738},
  Volume                   = {SE-10, no. 6},

  Key                      = {2007}
}

@Conference{Bavota201581,
  Title                    = {Four eyes are better than two: On the impact of code reviews on software quality},
  Author                   = {Bavota, G. and Russo, B.},
  Year                     = {2015},
  Pages                    = {81-90},

  Abstract                 = {Code review is advocated as one of the best practices to improve software quality and reduce the likelihood of introducing defects during code change activities. Recent research has shown how code components having a high review coverage (i.e., a high proportion of reviewed changes) tend to be less involved in post-release fixing activities. Yet the relationship between code review and bug introduction or the overall software quality is still largely unexplored. This paper presents an empirical, exploratory study on three large open source systems that aims at investigating the influence of code review on (i) the chances of inducing bug fixes and (ii) the quality of the committed code components, as assessed by code coupling, complexity, and readability. Findings show that unreviewed commits (i.e., commits that did not undergo a review process) have over two times more chances of introducing bugs than reviewed commits (i.e., commits that underwent a review process). In addition, code committed after review has a substantially higher readability with respect to unreviewed code. {\copyright} 2015 IEEE.},
  Affiliation              = {Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Italy},
  Art_number               = {7332454},
  Author_keywords          = {Code Review; Empirical Studies; Mining Software Repositories},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/ICSM.2015.7332454},
  Journal                  = {2015 IEEE 31st International Conference on Software Maintenance and Evolution, ICSME 2015 - Proceedings},
  Source                   = {Scopus}
}

@Conference{Baysal2013122,
  Title                    = {The influence of non-technical factors on code review},
  Author                   = {Baysal, O. and Kononenko, O. and Holmes, R. and Godfrey, M.W.},
  Year                     = {2013},
  Pages                    = {122-131},

  Abstract                 = {When submitting a patch, the primary concerns of individual developers are 'How can I maximize the chances of my patch being approved, and minimize the time it takes for this to happen?' In principle, code review is a transparent process that aims to assess qualities of the patch by their technical merits and in a timely manner; however, in practice the execution of this process can be affected by a variety of factors, some of which are external to the technical content of the patch itself. In this paper, we describe an empirical study of the code review process for WebKit, a large, open source project; we replicate the impact of previously studied factors - such as patch size, priority, and component and extend these studies by investigating organizational (the company) and personal dimensions (reviewer load and activity, patch writer experience) on code review response time and outcome. Our approach uses a reverse engineered model of the patch submission process and extracts key information from the issue tracking and code review systems. Our findings suggest that these nontechnical factors can significantly impact code review outcomes. {\copyright} 2013 IEEE.},
  Affiliation              = {David R. Cheriton School of Computer Science, University of Waterloo, Canada},
  Art_number               = {6671287},
  Author_keywords          = {Code review; non-technical factors; open source software; personal and organizational aspects; webkit},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/WCRE.2013.6671287},
  Journal                  = {Proceedings - Working Conference on Reverse Engineering, WCRE},
  Source                   = {Scopus}
}

@InProceedings{6385140,
  author    = {O. Baysal and O. Kononenko and R. Holmes and M. W. Godfrey},
  title     = {The Secret Life of Patches: A Firefox Case Study},
  booktitle = {2012 19th Working Conference on Reverse Engineering},
  year      = {2012},
  pages     = {447-455},
  abstract  = {The goal of the code review process is to assess the quality of source code modifications (submitted as patches) before they are committed to a project's version control repository. This process is particularly important in open source projects to ensure the quality of contributions submitted by the community, however, the review process can promote or discourage these contributions. In this paper, we study the patch lifecycle of the Mozilla Fire fox project. The model of a patch lifecycle was extracted from both the qualitative evidence of the individual processes (interviews and discussions with developers), and the quantitative assessment of the Mozilla process and practice. We contrast the lifecycle of a patch in pre- and post-rapid release development. A quantitative comparison showed that while the patch lifecycle remains mostly unchanged after switching to rapid release, the patches submitted by casual contributors are disproportionately more likely to be abandoned compared to core contributors. This suggests that patches from casual developers should receive extra care to both ensure quality and encourage future community contributions.},
  doi       = {10.1109/WCRE.2012.54},
  issn      = {1095-1350},
}

@Conference{Beller2014202,
  Title                    = {Modern code reviews in open-source projects: Which problems do they fix?},
  Author                   = {Beller, M.a and Bacchelli, A.a and Zaidman, A.a and Juergens, E.b},
  Year                     = {2014},
  Pages                    = {202-211},

  Abstract                 = {Code review is the manual assessment of source code by humans, mainly intended to identify defects and quality problems. Modern Code Review (MCR), a lightweight variant of the code inspections investigated since the 1970s, prevails today both in industry and open-source software (OSS) systems. The objective of this paper is to increase our understanding of the practical benefits that the MCR process produces on reviewed source code. To that end, we empirically explore the problems fixed through MCR in OSS systems. We manually classified over 1,400 changes taking place in reviewed code from two OSS projects into a validated categorization scheme. Surprisingly, results show that the types of changes due to the MCR process in OSS are strikingly similar to those in the industry and academic systems from literature, featuring the similar 75:25 ratio of maintainability-related to functional problems. We also reveal that 7-35% of review comments are discarded and that 10-22% of the changes are not triggered by an explicit review comment. Patterns emerged in the review data; we investigated them revealing the technical factors that influence the number of changes due to the MCR process. We found that bug-fixing tasks lead to fewer changes and tasks with more altered files and a higher code churn have more changes. Contrary to intuition, the person of the reviewer had no impact on the number of changes. Copyright is held by the author/owner(s). Publication rights licensed to ACM.},
  Affiliation              = {Delft University of Technology, Netherlands; CQSE GmbH, Germany},
  Author_keywords          = {Code review; Defects; Open source software},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2597073.2597082},
  Journal                  = {11th Working Conference on Mining Software Repositories, MSR 2014 - Proceedings},
  Source                   = {Scopus}
}

@InProceedings{van2010,
  Title                    = {Software ecosystems: a software ecosystem strategy assessment model},
  Author                   = {van den Berk, Ivo and Jansen, Slinger and Luinenburg, L{\'u}tzen},
  Booktitle                = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
  Year                     = {2010},
  Organization             = {ACM},
  Pages                    = {127--134}
}

@Conference{Bernhart2011182,
  Title                    = {A task-based code review process and tool to comply with the DO-278/ED-109 standard for Air Traffic Managment software development - An industrial case study},
  Author                   = {Bernhart, M. and Reiterer, S. and Matt, K. and Mauczka, A. and Grechenig, T.},
  Year                     = {2011},
  Pages                    = {182-187},

  Abstract                 = {Software reviews are one of the most efficient quality assurance techniques in software engineering. They are required for the enhancement of the software quality in early phases of the development process and often used in development of safety critical systems. In the field of software engineering for Air Traffic Management (ATM) the standard DO-278/ED-109 requires the rigorous application of code reviews and fully traceable reporting of the results. This case study presents a process and an IDE-integrated tool that complies with the requirements of the standard. {\copyright} 2011 IEEE.},
  Affiliation              = {Research Group for Industrial Software (INSO), Vienna University of Technology, Vienna, Austria},
  Art_number               = {6113895},
  Author_keywords          = {Air Traffic Management; Code inspection; Code review; DO-278; ED-109},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/HASE.2011.54},
  Journal                  = {Proceedings of IEEE International Symposium on High Assurance Systems Engineering},
  Source                   = {Scopus}
}

@Conference{Bird2015191,
  Title                    = {Lessons learned from building and deploying a code review analytics platform},
  Author                   = {Bird, C. and Carnahan, T. and Greiler, M.},
  Year                     = {2015},
  Pages                    = {191-201},
  Volume                   = {2015},

  Abstract                 = {Tool-based code review is growing in popularity and has become a standard part of the development process at Mi-crosoft. Adoption of these tools makes it possible to mine data from code reviews and provide access to it. In this paper, we pre-sent an experience report for CodeFlow Analytics, a system that collects code review data, generates metrics from this data, and provides a number of ways for development teams to access the metrics and data. We discuss the design, design decisions and chal-lenges that we encountered when building CodeFlow Analytics. We contacted teams that used CodeFlow Analytics over the past two years and discuss what prompted them to use CodeFlow Ana-lytics, how they have used it, and what the impact has been. Fur-ther, we survey research that has been enabled by using the Code-Flow Analytics platform. We provide a series of lessons learned from this experience to help others embarking on a task of building an analytics platform in an enterprise setting. {\copyright} 2015 IEEE.},
  Affiliation              = {Microsoft, Redmond, WA, United States},
  Art_number               = {7180079},
  Author_keywords          = {Computational modeling; Data mining; Databases; Interviews; Measurement; Servers; Software},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/MSR.2015.25},
  Journal                  = {IEEE International Working Conference on Mining Software Repositories},
  Source                   = {Scopus}
}

@Article{bobadilla2013,
  Title                    = {Recommender systems survey},
  Author                   = {Bobadilla, Jes{\'u}s and Ortega, Fernando and Hernando, Antonio and Guti{\'e}rrez, Abraham},
  Journal                  = {Knowledge-based systems},
  Year                     = {2013},
  Pages                    = {109--132},
  Volume                   = {46},

  Publisher                = {Elsevier}
}

@Article{Boehm2001,
  Title                    = {Software Defect Reduction Top 10 List},
  Author                   = {Boehm, Barry and Basili, Victor R.},
  Journal                  = {Computer},
  Year                     = {2001},

  Month                    = {12},
  Number                   = {1},
  Pages                    = {135-137},
  Volume                   = {34},

  Acmid                    = {621640},
  Address                  = {Los Alamitos, CA, USA},
  Doi                      = {10.1109/2.962984},
  ISSN                     = {0018-9162},
  Issue_date               = {January 2001},
  Numpages                 = {3},
  Publisher                = {IEEE Computer Society Press}
}

@Book{bosch2017,
  Title                    = {Speed, Data, and Ecosystems: Excelling in a Software-Driven World},
  Author                   = {Bosch, Jan},
  Publisher                = {CRC Press},
  Year                     = {2017}
}

@InProceedings{bosch2010,
  Title                    = {Architecture challenges for software ecosystems},
  Author                   = {Bosch, Jan},
  Booktitle                = {Proceedings of the Fourth European Conference on Software Architecture: Companion Volume},
  Year                     = {2010},
  Organization             = {ACM},
  Pages                    = {93--95}
}

@Conference{Bosu2014,
  Title                    = {Impact of developer reputation on code review outcomes in OSS projects: An empirical investigation},
  Author                   = {Bosu, A. and Carver, J.C.},
  Year                     = {2014},

  Abstract                 = {Context: Gaining an identity and building a good reputation are important motivations for Open Source Software (OSS) developers. It is unclear whether these motivations have any actual impact on OSS project success. Goal: To identify how an OSS developer's reputation affects the outcome of his/her code review requests. Method: We conducted a social network analysis (SNA) of the code review data from eight popular OSS projects. Working on the assumption that core developers have better reputation than peripheral developers, we developed an approach, Core Identification using K-means (CIK) to divide the OSS developers into core and periphery groups based on six SNA centrality measures. We then compared the outcome of the code review process for members of the two groups. Results: The results suggest that the core developers receive quicker first feedback on their review request, complete the review process in shorter time, and are more likely to have their code changes accepted into the project codebase. Peripheral developers may have to wait 2 - 19 times (or 12 - 96 hours) longer than core developers for the review process of their code to complete. Conclusion: We recommend that projects allocate resources or create tool support to triage the code review requests to motivate prospective developers through quick feedback. {\copyright} 2014 ACM.},
  Affiliation              = {Department of Computer Science, University of Alabama, Tuscaloosa, AL, United States},
  Art_number               = {a33},
  Author_keywords          = {code review; network structure; open source; peer impression; social network analysis},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2652524.2652544},
  Journal                  = {International Symposium on Empirical Software Engineering and Measurement},
  Source                   = {Scopus}
}

@Article{christensen2014,
  Title                    = {Analysis and design of software ecosystem architectures--Towards the 4S telemedicine ecosystem},
  Author                   = {Christensen, Henrik B{\ae}rbak and Hansen, Klaus Marius and Kyng, Morten and Manikas, Konstantinos},
  Journal                  = {Information and Software Technology},
  Year                     = {2014},
  Number                   = {11},
  Pages                    = {1476--1492},
  Volume                   = {56},

  Publisher                = {Elsevier}
}

@Article{dubey2007,
  Title                    = {Delivering software as a service},
  Author                   = {Dubey, Abhijit and Wagle, Dilip},
  Journal                  = {The McKinsey Quarterly},
  Year                     = {2007},
  Number                   = {2007},
  Pages                    = {2007},
  Volume                   = {6}
}

@Article{dybaa2006,
  Title                    = {A systematic review of statistical power in software engineering experiments},
  Author                   = {Dyb{\aa}, Tore and Kampenes, Vigdis By and Sj{\o}berg, Dag IK},
  Journal                  = {Information and Software Technology},
  Year                     = {2006},
  Number                   = {8},
  Pages                    = {745--755},
  Volume                   = {48},

  Publisher                = {Elsevier}
}

@Article{Fagan1976,
  Title                    = {Design and Code Inspections to Reduce Errors in Program Development},
  Author                   = {Fagan, M. E.},
  Journal                  = {IBM Syst. J.},
  Year                     = {1976},

  Month                    = {09},
  Number                   = {3},
  Pages                    = {182-211},
  Volume                   = {15},

  Acmid                    = {1661012},
  Address                  = {Riverton, NJ, USA},
  Doi                      = {10.1147/sj.153.0182},
  ISSN                     = {0018-8670},
  Issue_date               = {September 1976},
  Numpages                 = {30},
  Publisher                = {IBM Corp.}
}

@Article{fielding2002,
  Title                    = {Principled design of the modern Web architecture},
  Author                   = {Fielding, Roy T and Taylor, Richard N},
  Journal                  = {ACM Transactions on Internet Technology (TOIT)},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {115--150},
  Volume                   = {2},

  Publisher                = {ACM}
}

@Article{fowler2010,
  Title                    = {Richardson Maturity Model: steps toward the glory of REST},
  Author                   = {Fowler, Martin},
  Journal                  = {Online at http://martinfowler.com/articles/richardsonMaturityModel. html},
  Year                     = {2010}
}

@Book{Fowler1999,
  Title                    = {Refactoring: Improving the Design of Existing Code},
  Author                   = {Fowler, M. and Beck, K. and Brant, J. and Opdyke, W. and Roberts, D.},
  Publisher                = {Addison-Wesley Longman Publishing Co., Inc.},
  Year                     = {1999},

  ISBN                     = {0-201-48567-2}
}

@Booklet{frost2013,
  Title                    = {Using Hypothesis Tests to Bust Myths about the Battle of the Sexes},

  Author                   = {Jim Frost},
  Note                     = {[Online; Accessed 12/06/2017]},
  Year                     = {2013},

  Url                      = {http://blog.minitab.com/blog/adventures-in-statistics-2/using-hyp\\othesis-tests-to-bust-myths-about-the-battle-of-the-sexes}
}

@InProceedings{Fuggetta2014,
  Title                    = {Software Process},
  Author                   = {Fuggetta, Alfonso and Di Nitto, Elisabetta},
  Booktitle                = {Proceedings of the on Future of Software Engineering},
  Year                     = {2014},

  Address                  = {New York, NY, USA},
  Pages                    = {1--12},
  Publisher                = {ACM},
  Series                   = {FOSE 2014},

  Acmid                    = {2593883},
  Doi                      = {10.1145/2593882.2593883},
  ISBN                     = {978-1-4503-2865-4},
  Keywords                 = {Agile Software De- velopment, Empirical Studies, Social Fac- tors in Software Development, Software Development, Software Development Environments, Software Process},
  Location                 = {Hyderabad, India},
  Numpages                 = {12},
  Url                      = {http://doi.acm.org/10.1145/2593882.2593883}
}

@Book{Gamma1995,
  Title                    = {Design Patterns: Elements of Reusable Object-oriented Software},
  Author                   = {Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John},
  Publisher                = {Addison-Wesley Longman Publishing Co., Inc.},
  Year                     = {1995},

  Address                  = {Boston, MA, USA},

  ISBN                     = {0-201-63361-2}
}

@Booklet{google2017,
  Title                    = {Material design - Introduction},

  Author                   = {Google},
  HowPublished             = {https://material.io/guidelines/#introduction-goals},
  Note                     = {Accessed 2017-05-24},
  Year                     = {2017}
}

@InProceedings{gousios2014,
  Title                    = {An exploratory study of the pull-based software development model},
  Author                   = {Gousios, Georgios and Pinzger, Martin and Deursen, Arie van},
  Booktitle                = {Proceedings of the 36th International Conference on Software Engineering},
  Year                     = {2014},
  Organization             = {ACM},
  Pages                    = {345--355}
}

@InProceedings{gousios2016,
  Title                    = {Work practices and challenges in pull-based development: The contributor's perspective},
  Author                   = {Gousios, Georgios and Storey, Margaret-Anne and Bacchelli, Alberto},
  Booktitle                = {Software Engineering (ICSE), 2016 IEEE/ACM 38th International Conference on},
  Year                     = {2016},
  Organization             = {IEEE},
  Pages                    = {285--296}
}

@Booklet{Guardian2014,
  Title                    = {Spotify: five big challenges looming for the streaming music service},

  Author                   = {The Guardian},
  HowPublished             = {https://www.theguardian.com/technology/2014/may/21/spotify-five-big-challenges-streaming-music/},
  Note                     = {Accessed 2017-05-01},
  Year                     = {2014}
}

@Article{hardt2012,
  Title                    = {The OAuth 2.0 authorization framework},
  Author                   = {Hardt, Dick},
  Year                     = {2012}
}

@Article{jansen2013,
  Title                    = {Defining software ecosystems: a survey of software platforms and business network governance},
  Author                   = {Jansen, Slinger and Cusumano, Michael A},
  Journal                  = {Software ecosystems: analyzing and managing business networks in the software industry},
  Year                     = {2013},
  Volume                   = {13},

  __markedentry            = {[vschettino:1]},
  Publisher                = {Edward Elgar Pub}
}

@InProceedings{jansen2009,
  Title                    = {A sense of community: A research agenda for software ecosystems},
  Author                   = {Jansen, Slinger and Finkelstein, Anthony and Brinkkemper, Sjaak},
  Booktitle                = {Software Engineering-Companion Volume, 2009. ICSE-Companion 2009. 31st International Conference on},
  Year                     = {2009},
  Organization             = {IEEE},
  Pages                    = {187--190}
}

@InProceedings{Jansen2013,
  author    = {Jansen, Slinger and Peeters, Stef and Brinkkemper, Sjaak},
  title     = {Software Ecosystems: From Software Product Management to Software Platform Management.},
  booktitle = {IW-LCSP@ ICSOB},
  year      = {2013},
  pages     = {5--18},
}

@Article{jarke2011,
  Title                    = {The brave new world of design requirements},
  Author                   = {Jarke, Matthias and Loucopoulos, Pericles and Lyytinen, Kalle and Mylopoulos, John and Robinson, William},
  Journal                  = {Information Systems},
  Year                     = {2011},
  Number                   = {7},
  Pages                    = {992--1008},
  Volume                   = {36},

  Publisher                = {Elsevier}
}

@Article{Kemerer2009,
  Title                    = {The Impact of Design and Code Reviews on Software Quality: An Empirical Study Based on PSP Data},
  Author                   = {C. F. Kemerer and M. C. Paulk},
  Journal                  = {IEEE Transactions on Software Engineering},
  Year                     = {2009},

  Month                    = {07},
  Number                   = {4},
  Pages                    = {534-550},
  Volume                   = {35},

  Abstract                 = {This research investigates the effect of review rate on defect removal effectiveness and the quality of software products, while controlling for a number of potential confounding factors. Two data sets of 371 and 246 programs, respectively, from a personal software process (PSP) approach were analyzed using both regression and mixed models. Review activities in the PSP process are those steps performed by the developer in a traditional inspection process. The results show that the PSP review rate is a significant factor affecting defect removal effectiveness, even after accounting for developer ability and other significant process variables. The recommended review rate of 200 LOC/hour or less was found to be an effective rate for individual reviews, identifying nearly two-thirds of the defects in design reviews and more than half of the defects in code reviews.},
  Doi                      = {10.1109/TSE.2009.27},
  ISSN                     = {0098-5589}
}

@Article{Kitcheham2007,
  author  = {Kitchenham, B. and Charters, S.},
  title   = {Guidelines for performing systematic literature reviews in software engineering},
  journal = {Tech. report, Ver. 2.3 EBSE},
  year    = {2007},
  volume  = {9},
  number  = {9},
  pages   = {9},
  key     = {2007},
}

@Article{kitchenham2004,
  Title                    = {Procedures for performing systematic reviews},
  Author                   = {Kitchenham, Barbara},
  Journal                  = {Keele, UK, Keele University},
  Year                     = {2004},
  Number                   = {2004},
  Pages                    = {1--26},
  Volume                   = {33}
}

@InProceedings{Kitchenham2006,
  Title                    = {Evaluating Guidelines for Empirical Software Engineering Studies},
  Author                   = {Kitchenham, Barbara and Al-Khilidar, Hiyam and Babar, Muhammad Ali and Berry, Mike and Cox, Karl and Keung, Jacky and Kurniawati, Felicia and Staples, Mark and Zhang, He and Zhu, Liming},
  Booktitle                = {Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering},
  Year                     = {2006},

  Address                  = {New York, NY, USA},
  Pages                    = {38--47},
  Publisher                = {ACM},
  Series                   = {ISESE '06},

  Acmid                    = {1159742},
  Doi                      = {10.1145/1159733.1159742},
  ISBN                     = {1-59593-218-6},
  Keywords                 = {controlled experiments, guidelines, perspective-based inspection, software engineering},
  Location                 = {Rio de Janeiro, Brazil},
  Numpages                 = {10},
  Url                      = {http://doi.acm.org/10.1145/1159733.1159742}
}

@InProceedings{kjernsmo2012,
  Title                    = {The necessity of hypermedia RDF and an approach to achieve it},
  Author                   = {Kjernsmo, Kjetil},
  Booktitle                = {Proceedings of the First Linked APIs workshop at the Ninth Extended Semantic Web Conference},
  Year                     = {2012}
}

@Conference{Kononenko2015111,
  Title                    = {Investigating code review quality: Do people and participation matter?},
  Author                   = {Kononenko, O.a and Baysal, O.b and Guerrouj, L.c and Cao, Y.b and Godfrey, M.W.a},
  Year                     = {2015},
  Pages                    = {111-120},

  Abstract                 = {Code review is an essential element of any mature software development project; it aims at evaluating code contributions submitted by developers. In principle, code review should improve the quality of code changes (patches) before they are committed to the project's master repository. In practice, bugs are sometimes unwittingly introduced during this process. In this paper, we report on an empirical study investigating code review quality for Mozilla, a large open-source project. We explore the relationships between the reviewers' code inspections and a set of factors, both personal and social in nature, that might affect the quality of such inspections. We applied the SZZ algorithm to detect bug-inducing changes that were then linked to the code review information extracted from the issue tracking system. We found that 54% of the reviewed changes introduced bugs in the code. Our findings also showed that both personal metrics, such as reviewer workload and experience, and participation metrics, such as the number of involved developers, are associated with the quality of the code review process. {\copyright} 2015 IEEE.},
  Affiliation              = {David R. Cheriton School of Computer Science, University of Waterloo, Canada; Department of Computer Science and Operations Research, Université de Montréal, Canada; Département de Génie Logiciel et des Technologies de l'Information, École de Technologie Supérieure, Canada},
  Art_number               = {7332457},
  Author_keywords          = {bug-inducing changes; Code review; code review quality; empirical study; mining software repositories; Mozilla},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/ICSM.2015.7332457},
  Journal                  = {2015 IEEE 31st International Conference on Software Maintenance and Evolution, ICSME 2015 - Proceedings},
  Source                   = {Scopus}
}

@Article{kruchten2012,
  Title                    = {Technical debt: From metaphor to theory and practice},
  Author                   = {Kruchten, Philippe and Nord, Robert L and Ozkaya, Ipek},
  Journal                  = {Ieee software},
  Year                     = {2012},
  Number                   = {6},
  Pages                    = {18--21},
  Volume                   = {29},

  Publisher                = {IEEE}
}

@Booklet{Labs2017,
  Title                    = {Spotify Business Model and How does Spotify Make Money},

  Author                   = {Redis Labs},
  HowPublished             = {https://redis.io/topics/persistence#append-only-file},
  Note                     = {Accessed 2017-05-24},
  Year                     = {2017}
}

@Booklet{redis2017,
  Title                    = {Redis Persistence},

  Author                   = {Redis Labs},
  HowPublished             = {https://redis.io/topics/persistence#append-only-file},
  Note                     = {Accessed 2017-05-24},
  Year                     = {2017}
}

@InProceedings{letouzey2012,
  Title                    = {The SQALE method for evaluating technical debt},
  Author                   = {Letouzey, Jean-Louis},
  Booktitle                = {Managing Technical Debt (MTD), 2012 Third International Workshop on},
  Year                     = {2012},
  Organization             = {IEEE},
  Pages                    = {31-36}
}

@Article{manikas2016,
  Title                    = {Revisiting software ecosystems research: A longitudinal literature study},
  Author                   = {Manikas, Konstantinos},
  Journal                  = {Journal of Systems and Software},
  Year                     = {2016},
  Pages                    = {84--103},
  Volume                   = {117},

  Publisher                = {Elsevier}
}

@Article{manikas2015,
  Title                    = {Defining decision making strategies in software ecosystem governance},
  Author                   = {Manikas, Konstantinos and Wnuk, Krysztof and Shollo, Arisa},
  Journal                  = {Department of Computer Science, University of Copenhagen},
  Year                     = {2015}
}

@Conference{McIntosh2014192,
  Title                    = {The impact of code review coverage and code review participation on Software quality: A case study of the Qt, VTK, and ITK projects},
  Author                   = {McIntosh, Shane and Kamei, Yasutaka and Adams, Bram and Hassan, Ahmed E.},
  Year                     = {2014},
  Pages                    = {192-201},

  Abstract                 = {Software code review, i.e., the practice of having third-party team members critique changes to a software system, is a well-established best practice in both open source and proprietary software domains. Prior work has shown that the formal code inspections of the past tend to improve the quality of software delivered by students and small teams. However, the formal code inspection process mandates strict review criteria (e.g., in-person meetings and reviewer checklists) to ensure a base level of review quality, while the modern, lightweight code reviewing process does not. Although recent work explores the modern code review process qualitatively, little research quantitatively explores the relationship between properties of the modern code review process and software quality. Hence, in this paper, we study the relationship between software quality and: (1) code review coverage, i.e., the proportion of changes that have been code reviewed, and (2) code review participation, i.e., the degree of reviewer involvement in the code review process. Through a case study of the Qt, VTK, and ITK projects, we find that both code review coverage and participation share a significant link with software quality. Low code review coverage and participation are estimated to produce components with up to two and five additional post-release defects respectively. Our results empirically confirm the intuition that poorly reviewed code has a negative impact on software quality in large systems using modern reviewing tools. Copyright 2014 ACM.},
  Affiliation              = {Queen's University, Canada; Kyushu University, Japan; Polytechnique Montréal, Canada},
  Author_keywords          = {Code reviews; Software quality},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2597073.2597076},
  Journal                  = {11th Working Conference on Mining Software Repositories, MSR 2014 - Proceedings},
  Source                   = {Scopus}
}

@Conference{Meneely201437,
  Title                    = {An empirical investigation of socio-technical code review metrics and security vulnerabilities},
  Author                   = {Meneely, A. and Tejeda, A.C.R. and Spates, B. and Trudeau, S. and Neuberger, D. and Whitlock, K. and Ketant, C. and Davis, K.},
  Year                     = {2014},
  Pages                    = {37-44},

  Abstract                 = {One of the guiding principles of open source software development is to use crowds of developers to keep a watchful eye on source code. Eric Raymond declared Linus' Law as "many eyes make all bugs shallow", with the socio-technical argument that high quality open source software emerges when developers combine together their collective experience and expertise to review code collaboratively. Vulnerabilities are a particularly nasty set of bugs that can be rare, difficult to reproduce, and require specialized skills to recognize. Does Linus' Law apply to vulnerabilities empirically? In this study, we analyzed 159,254 code reviews, 185,948 Git commits, and 667 post-release vulnerabilities in the Chromium browser project. We formulated, collected, and analyzed various metrics related to Linus' Law to explore the connection between collaborative reviews and vulnerabilities that were missed by the review process. Our statistical association results showed that source code files reviewed by more developers are, counter-intuitively, more likely to be vulnerable (even after accounting for file size). However, files are less likely to be vulnerable if they were reviewed by developers who had experience participating on prior vulnerability-fixing reviews. The results indicate that lack of security experience and lack of collaborator familiarity are key risk factors in considering Linus' Law with vulnerabilities. Copyright 2014 ACM.},
  Affiliation              = {Department of Software Engineering, Rochester Institute of Technology, 134 Lomb Memorial Drive, Rochester, NY, United States},
  Author_keywords          = {Code review; Socio-technical; Vulnerability},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2661685.2661687},
  Journal                  = {6th International Workshop on Social Software Engineering, SSE 2014 - Proceedings},
  Source                   = {Scopus}
}

@Booklet{Mic2016,
  Title                    = {How Does Spotify Make Money? Here's the Business Model Behind the Streaming Service},

  Author                   = {Mic},
  HowPublished             = {https://mic.com/articles/137400/how-does-spotify-make-money-here-s-the-business-model-behind-the-streaming-service},
  Note                     = {Accessed 2017-05-24},
  Year                     = {2016}
}

@Article{miller1997,
  Title                    = {Statistical power and its subcomponents—missing and misunderstood concepts in empirical software engineering research},
  Author                   = {Miller, James and Daly, John and Wood, Murray and Roper, Marc and Brooks, Andrew},
  Journal                  = {Information and Software Technology},
  Year                     = {1997},
  Number                   = {4},
  Pages                    = {285--295},
  Volume                   = {39},

  Publisher                = {Elsevier}
}

@Conference{Mishra201411,
  Title                    = {Mining peer code review system for computing effort and contribution metrics for patch reviewers},
  Author                   = {Mishra, R. and Sureka, A.},
  Year                     = {2014},
  Pages                    = {11-15},

  Abstract                 = {Peer code review is a software quality assurance activity followed in several open-source and closed-source software projects. Rietveld and Gerrit are the most popular peer code review systems used by open-source software projects. Despite the popularity and usefulness of these systems, they do not record or maintain the cost and effort information for a submitted patch review activity. Currently there are no formal or standard metrics available to measure effort and contribution of a patch review activity. We hypothesize that the size and complexity of modified files and patches are significant indicators of effort and contribution of patch reviewers in a patch review process. We propose a metric for computing the effort and contribution of a patch reviewer based on modified file size, patch size and program complexity variables. We conduct a survey of developers involved in peer code review activity to test our hypothesis of causal relationship between proposed indicators and effort. We employ the proposed model and conduct an empirical analysis using the proposed metrics on open-source Google Android project. {\copyright} 2014 IEEE.},
  Affiliation              = {Indraprastha Institute of Information Technology, Delhi (IIITD), New Delhi, India},
  Art_number               = {6980189},
  Author_keywords          = {Contribution and Performance Assessment; Empirical Software Engineering and Measurements; Mining Software Repositories; Peer Code Review; Software Maintenance},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/MUD.2014.11},
  Journal                  = {2014 4th IEEE Workshop on Mining Unstructured Data, MUD 2014},
  Source                   = {Scopus}
}

@Article{Morales2015171,
  Title                    = {Do code review practices impact design quality? A case study of the Qt, VTK, and ITK projects},
  Author                   = {Rodrigo Morales and Shane McIntosh and Foutse Khomh},
  Journal                  = {2015 IEEE 22nd International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  Year                     = {2015},
  Pages                    = {171-180},
  Volume                   = {00},

  Address                  = {Los Alamitos, CA, USA},
  Publisher                = {IEEE Computer Society}
}

@TechReport{murphy2008,
  Title                    = {Best practices for verification, validation, and test in model-based design},
  Author                   = {Murphy, Brett and Wakefield, Amory and Friedman, Jon},
  Institution              = {SAE Technical Paper},
  Year                     = {2008}
}

@Booklet{pensu2017,
  Title                    = {Tests for Error Normality},

  Author                   = {{Pennsylvania State University}},
  Note                     = {[Online; Accessed 12/06/2017]},
  Year                     = {2017},

  Url                      = {https://onlinecourses.science.psu.edu/stat501/node/366}
}

@Booklet{pensu2017b,
  Title                    = {Lesson 9: Comparing Two Groups},

  Author                   = {{Pennsylvania State University}},
  Note                     = {[Online; Accessed 12/06/2017]},
  Year                     = {2017},

  Url                      = {https://onlinecourses.science.psu.edu/stat200/book/export/html/57}
}

@InProceedings{petersen2009,
  Title                    = {Context in industrial software engineering research},
  Author                   = {Petersen, Kai and Wohlin, Claes},
  Booktitle                = {Proceedings of the 2009 3rd international symposium on empirical software engineering and measurement},
  Year                     = {2009},
  Organization             = {IEEE Computer Society},
  Pages                    = {401--404}
}

@Book{Petticrew2008,
  Title                    = {Systematic reviews in the social sciences: A practical guide.},
  Author                   = {M. Petticrew and H. Roberts},
  Publisher                = {John Wiley and Sons},
  Year                     = {2008}
}

@InProceedings{prause2008,
  Title                    = {An approach for continuous inspection of source code},
  Author                   = {Prause, Christian R and Apelt, Stefan},
  Booktitle                = {Proceedings of the 6th international workshop on Software quality},
  Year                     = {2008},
  Organization             = {ACM},
  Pages                    = {17-22}
}

@Book{Raymond2001,
  Title                    = {The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary},
  Author                   = {Raymond, Eric S.},
  Publisher                = {O'Reilly and Associates, Inc.},
  Year                     = {2001},

  ISBN                     = {0-596-01008-8}
}

@InProceedings{richardson2008,
  Title                    = {Justice will take us millions of intricate moves},
  Author                   = {Richardson, Leonard},
  Booktitle                = {International Software Development Conference (QCon)},
  Year                     = {2008}
}

@PhdThesis{santos2016,
  Title                    = {Managing and monitoring software ecosystem to support demand and solution analysis},
  Author                   = {dos Santos, Rodrigo Pereira},
  School                   = {Universidade Federal do Rio de Janeiro},
  Year                     = {2016}
}

@InProceedings{Sjoberg2002,
  Title                    = {Conducting realistic experiments in software engineering},
  Author                   = {D. I. K. Sjoberg and B. Anda and E. Arisholm and T. Dyba and M. Jorgensen and A. Karahasanovic and E. F. Koren and M. Vokac},
  Booktitle                = {Proceedings International Symposium on Empirical Software Engineering},
  Year                     = {2002},
  Pages                    = {17-26},

  Doi                      = {10.1109/ISESE.2002.1166921}
}


@Booklet{SpotifyArtists2017a,
  Author                   = {Spotify},
  Title                    = {Spotify Artists FAQ},
  Year                     = {2017},
  Howpublished             = {https://artists.spotify.com/faq/},
  Note                     = {Accessed 2017-05-24}
}

@Booklet{SpotifyArtists2017b,
  Title                    = {Spotify Artists Blog},
  Author                   = {Spotify},
  HowPublished             = {https://artists.spotify.com/blog},
  Note                     = {Accessed 2017-05-24},
  Year                     = {2017}
}

@Booklet{SpotifyArtists2017c,
  Title                    = {Spotify Artists Guide},

  Author                   = {Spotify},
  HowPublished             = {https://artists.spotify.com/guide},
  Note                     = {Accessed 2017-06-02},
  Year                     = {2017}
}

@Booklet{SpotifyDevs2017a,
  Title                    = {Spotify Developers Showcase},

  Author                   = {Spotify},
  HowPublished             = {https://developer.spotify.com/showcase/},
  Note                     = {Accessed 2017-06-02},
  Year                     = {2017}
}

@Booklet{SpotifyDevs2017b,
  Title                    = {New Endpoint: Recently Played Tracks},

  Author                   = {Spotify},
  HowPublished             = {https://developer.spotify.com/news-stories/2017/03/01/new-endpoint-recently-played-tracks/},
  Note                     = {Accessed 2017-06-02},
  Year                     = {2017}
}

@Booklet{SpotifyLabs2017a,
  Title                    = {Understanding the Spotify Web API},

  Author                   = {Spotify},
  HowPublished             = {https://labs.spotify.com/2015/03/09/understanding-spotify-web-api/},
  Note                     = {Accessed 2017-06-02},
  Year                     = {2017}
}

@Booklet{Telegraph2015,
  Title                    = {Apple Music vs Spotify: How do the two streaming services compare? },

  Author                   = {The Telegraph},
  HowPublished             = {http://www.telegraph.co.uk/technology/2016/03/17/apple-music-vs-spotify-how-do-the-two-streaming-services-compare/},
  Note                     = {Accessed 2017-05-01},
  Year                     = {2015}
}

@Conference{Thongtanunam2014119,
  Title                    = {Improving code review effectiveness through reviewer recommendations},
  Author                   = {Thongtanunam, P.a and Kula, R.G.b and Cruz, A.E.C.a and Yoshida, N.a and Iida, H.a},
  Year                     = {2014},
  Pages                    = {119-122},

  Abstract                 = {Effectively performing code review increases the quality of software and reduces occurrence of defects. However, this requires reviewers with experiences and deep understandings of system code. Manual selection of such reviewers can be a costly and time-consuming task. To reduce this cost, we propose a reviewer recommendation algorithm determining file path similarity called FPS algorithm. Using three OSS projects as case studies, FPS algorithm was accurate up to 77.97%, which significantly outperformed the previous approach. Copyright 2014 ACM.},
  Affiliation              = {Nara Institute of Science and Technology, Japan; Osaka University, Japan},
  Author_keywords          = {Open source software; Peer code review; Recommendation system; Software quality},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2593702.2593705},
  Journal                  = {8th International Workshop on Cooperative and Human Aspects of Software Engineering, CHASE 2014 - Proceedings},
  Source                   = {Scopus}
}

@Conference{Thongtanunam2015168,
  Title                    = {Investigating code review practices in defective files: An empirical study of the Qt system},
  Author                   = {Thongtanunam, P.a and McIntosh, S.b and Hassan, A.E.b and Iida, H.a},
  Year                     = {2015},
  Pages                    = {168-179},
  Volume                   = {2015},

  Abstract                 = {Software code review is a well-established software quality practice. Recently, Modern Code Review (MCR) has been widely adopted in both open source and proprietary projects. To evaluate the impact that characteristics of MCR practices have on software quality, this paper comparatively studies MCR practices in defective and clean source code files. We investigate defective files along two perspectives: 1) files that will eventually have defects (i.e., Future-defective files) and 2) files that have historically been defective (i.e., Risky files). Through an empirical study of 11,736 reviews of changes to 24,486 files from the Qt open source project, we find that both future-defective files and risky files tend to be reviewed less rigorously than their clean counterparts. We also find that the concerns addressed during the code reviews of both defective and clean files tend to enhance evolvability, i.e., Ease future maintenance (like documentation), rather than focus on functional issues (like incorrect program logic). Our findings suggest that although functionality concerns are rarely addressed during code review, the rigor of the reviewing process that is applied to a source code file throughout a development cycle shares a link with its defect proneness. {\copyright} 2015 IEEE.},
  Affiliation              = {Nara Institute of Science and Technology, Japan; Queen's University, Canada},
  Art_number               = {7180077},
  Author_keywords          = {Code Review; Software Quality},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/MSR.2015.23},
  Journal                  = {IEEE International Working Conference on Mining Software Repositories},
  Source                   = {Scopus}
}

@Conference{Thongtanunam2015141,
  Title                    = {Who should review my code? A file location-based code-reviewer recommendation approach for Modern Code Review},
  Author                   = {Thongtanunam, P.a and Tantithamthavorn, C.a and Kula, R.G.b and Yoshida, N.c and Iida, H.a and Matsumoto, K.-I.a},
  Year                     = {2015},
  Pages                    = {141-150},

  Abstract                 = {Software code review is an inspection of a code change by an independent third-party developer in order to identify and fix defects before an integration. Effectively performing code review can improve the overall software quality. In recent years, Modern Code Review (MCR), a lightweight and tool-based code inspection, has been widely adopted in both proprietary and open-source software systems. Finding appropriate code-reviewers in MCR is a necessary step of reviewing a code change. However, little research is known the difficulty of finding code-reviewers in a distributed software development and its impact on reviewing time. In this paper, we investigate the impact of reviews with code-reviewer assignment problem has on reviewing time. We find that reviews with code-reviewer assignment problem take 12 days longer to approve a code change. To help developers find appropriate code-reviewers, we propose RevFinder, a file location-based code-reviewer recommendation approach. We leverage a similarity of previously reviewed file path to recommend an appropriate code-reviewer. The intuition is that files that are located in similar file paths would be managed and reviewed by similar experienced code-reviewers. Through an empirical evaluation on a case study of 42,045 reviews of Android Open Source Project (AOSP), OpenStack, Qt and LibreOffice projects, we find that RevFinder accurately recommended 79% of reviews with a top 10 recommendation. RevFinder also correctly recommended the code-reviewers with a median rank of 4. The overall ranking of RevFinder is 3 times better than that of a baseline approach. We believe that RevFinder could be applied to MCR in order to help developers find appropriate code-reviewers and speed up the overall code review process. {\copyright} 2015 IEEE.},
  Affiliation              = {Nara Institute of Science and Technology, Japan; Osaka University, Japan; Nagoya University, Japan},
  Art_number               = {7081824},
  Author_keywords          = {Code-Reviewer Recommendation; Distributed Software Development; Modern Code Review},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/SANER.2015.7081824},
  Journal                  = {2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering, SANER 2015 - Proceedings},
  Source                   = {Scopus}
}

@Booklet{Unicornomy2016,
  Title                    = {Spotify Business Model and How does Spotify Make Money},

  Author                   = {Unicornomy},
  HowPublished             = {https://unicornomy.com/spotify-business-model-how-does-spotify-make-money/},
  Note                     = {Accessed 2017-05-24},
  Year                     = {2016}
}

@Article{Votta1993,
  Title                    = {Does Every Inspection Need a Meeting?},
  Author                   = {Votta,Jr. and Lawrence, G.},
  Journal                  = {SIGSOFT Softw. Eng. Notes},
  Year                     = {1993},

  Month                    = {12},
  Number                   = {5},
  Pages                    = {107-114},
  Volume                   = {18},

  Acmid                    = {167070},
  Address                  = {New York, NY, USA},
  Doi                      = {10.1145/167049.167070},
  ISSN                     = {0163-5948},
  Issue_date               = {Dec. 1993},
  Numpages                 = {8},
  Publisher                = {ACM}
}

@Booklet{wang2009,
  Title                    = {Using MINITAB},

  Author                   = {J.C. Wang},
  Note                     = {[Online; Accessed 12/06/2017]},
  Year                     = {2009},

  Url                      = {http://www.stat.wmich.edu/wang/664/egs/\\MTBrust.html}
}

@Article{weill2005,
  Title                    = {A matrixed approach to designing IT governance},
  Author                   = {Weill, Peter and Ross, Jeanne},
  Journal                  = {MIT Sloan Management Review},
  Year                     = {2005},
  Number                   = {2},
  Pages                    = {26},
  Volume                   = {46},

  Publisher                = {Massachusetts Institute of Technology, Cambridge, MA}
}

@Book{wohlin2012,
  Title                    = {Experimentation in software engineering},
  Author                   = {Wohlin, Claes and Runeson, Per and H{\"o}st, Martin and Ohlsson, Magnus C and Regnell, Bj{\"o}rn and Wessl{\'e}n, Anders},
  Publisher                = {Springer Science \& Business Media},
  Year                     = {2012}
}

@Booklet{MusicBusiness2016,
  Title                    = {Spotify is converting more people into paying subscribers than ever before},

  Author                   = {Music Business Worldwide},
  HowPublished             = {https://www.musicbusinessworldwide.com/spotify-is-converting-more-people-into-paying-customers-than-ever-before/},
  Note                     = {Accessed 2017-05-01},
  Year                     = {2016}
}

@Conference{Xia2015261,
  Title                    = {Who should review this change?: Putting text and file location analyses together for more accurate recommendations},
  Author                   = {Xia, X.a and Lo, D.b and Wang, X.a b and Yang, X.a },
  Booktitle                = {IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER 2016)},
  Year                     = {2015},
  Pages                    = {261-270},

  Abstract                 = {Software code review is a process of developers inspecting new code changes made by others, to evaluate their quality and identify and fix defects, before integrating them to the main branch of a version control system. Modern Code Review (MCR), a lightweight and tool-based variant of conventional code review, is widely adopted in both open source and proprietary software projects. One challenge that impacts MCR is the assignment of appropriate developers to review a code change. Considering that there could be hundreds of potential code reviewers in a software project, picking suitable reviewers is not a straightforward task. A prior study by Thongtanunam et al. showed that the difficulty in selecting suitable reviewers may delay the review process by an average of 12 days. In this paper, to address the challenge of assigning suitable reviewers to changes, we propose a hybrid and incremental approach Tie which utilizes the advantages of both Text mIning and a filE location-based approach. To do this, Tie integrates an incremental text mining model which analyzes the textual contents in a review request, and a similarity model which measures the similarity of changed file paths and reviewed file paths. We perform a large-scale experiment on four open source projects, namely Android, OpenStack, QT, and LibreOffice, containing a total of 42,045 reviews. The experimental results show that on average Tie can achieve top-1, top-5, and top-10 accuracies, and Mean Reciprocal Rank (MRR) of 0.52, 0.79, 0.85, and 0.64 for the four projects, which improves the state-of-the-art approach RevFinder, proposed by Thongtanunam et al., by 61%, 23%, 8%, and 37%, respectively. {\copyright} 2015 IEEE.},
  Affiliation              = {College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Information Systems, Singapore Management University, Singapore, Singapore},
  Art_number               = {7332472},
  Author_keywords          = {Modern Code Review; Path Similarity; Recommendation System; Text Mining},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/ICSM.2015.7332472},
  Journal                  = {2015 IEEE 31st International Conference on Software Maintenance and Evolution, ICSME 2015 - Proceedings},
  Source                   = {Scopus}
}

@article{nicolaci2011,
  title={Sistemas colaborativos para uma nova sociedade e um novo ser humano},
  author={Nicolaci-da-Costa, Ana Maria and Pimentel, Mariano},
  journal={Sistemas colaborativos. PIMENTEL, M.; FUKS, H.(Orgs.). Rio de Janeiro: Elsevier},
  year={2011}
}

@article{casey2010,
  title={Virtual software team project management},
  author={Casey, Valentine},
  journal={Journal of the Brazilian Computer Society},
  volume={16},
  number={2},
  pages={83--96},
  year={2010},
  publisher={Springer}
}

@article{prikladnicki2017,
author={R. Prikladnicki and M. G. Perin and S. Marczak and A. C. S. Dutra},
journal={IEEE Software},
title={The Best Software Development Teams Might be Temporary},
year={2017},
volume={34},
number={2},
pages={22-25},
keywords={project management;software development management;team working;software development projects;software development teams;team members;temporary teams;Computer crashes;Computer science;Maintenance engineering;Performance evaluation;Software development;Software quality;major releases;minor releases;software development;software development teams;software engineering},
doi={10.1109/MS.2017.50},
ISSN={0740-7459},
month={Mar},}

@book{page2008,
  title={The difference: How the power of diversity creates better groups, firms, schools, and societies},
  author={Page, Scott E},
  year={2008},
  publisher={Princeton University Press}
}

@article{fuks2003,
  title={Do modelo de colabora{\c{c}}{\~a}o 3c {\`a} engenharia de groupware},
  author={Fuks, Hugo and Raposo, Alberto Barbosa and Gerosa, Marco Aur{\'e}lio and Lucena, Carlos J Pereira},
  journal={Simp{\'o}sio Brasileiro de Sistemas Multim{\'\i}dia e Web--Webmidia},
  pages={0--8},
  year={2003}
}
@inproceedings{gousios2015,
  title={Work practices and challenges in pull-based development: the integrator's perspective},
  author={Gousios, Georgios and Zaidman, Andy and Storey, Margaret-Anne and Van Deursen, Arie},
  booktitle={Proceedings of the 37th International Conference on Software Engineering-Volume 1},
  pages={358--368},
  year={2015},
  organization={IEEE Press}
}
@book{audy2007,
  title={Desenvolvimento distribu{\'\i}do de software},
  author={Audy, Jorge Luis Nicolas and Prikladnicki, Rafael},
  year={2007},
  publisher={Elsevier}
}

@article{steinmacher2010,
  title={Awareness support in global software development: a systematic review based on the 3C collaboration model},
  author={Steinmacher, Igor and Chaves, Ana and Gerosa, Marco},
  journal={Collaboration and Technology},
  pages={185--201},
  year={2010},
  publisher={Springer}
}

@article{ellis1991,
  title={Groupware: some issues and experiences},
  author={Ellis, Clarence A and Gibbs, Simon J and Rein, Gail},
  journal={Communications of the ACM},
  volume={34},
  number={1},
  pages={39--58},
  year={1991},
  publisher={ACM}
}

@InProceedings{rahman2016,
  author       = {Rahman, Mohammad Masudur and Roy, Chanchal K and Collins, Jason A},
  title        = {CoRReCT: code reviewer recommendation in GitHub based on cross-project and technology experience},
  booktitle    = {Software Engineering Companion (ICSE-C), IEEE/ACM International Conference on},
  year         = {2016},
  pages        = {222--231},
  organization = {IEEE},
}

@InProceedings{yu2014,
  author       = {Yu, Yue and Wang, Huaimin and Yin, Gang and Ling, Charles X},
  title        = {Who should review this pull-request: Reviewer recommendation to expedite crowd collaboration},
  booktitle    = {Software Engineering Conference (APSEC), 2014 21st Asia-Pacific},
  year         = {2014},
  volume       = {1},
  pages        = {335--342},
  organization = {IEEE},
}

@InProceedings{balachandran2013,
  author       = {Balachandran, Vipin},
  title        = {Reducing human effort and improving quality in peer code reviews using automatic static analysis and reviewer recommendation},
  booktitle    = {Software Engineering (ICSE), 2013 35th International Conference on},
  year         = {2013},
  pages        = {931--940},
  organization = {IEEE},
}

@InProceedings{costa2016,
  author       = {Costa, Catarina and Figueiredo, Jair and Murta, Leonardo and Sarma, Anita},
  title        = {TIPMerge: recommending experts for integrating changes across branches},
  booktitle    = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  year         = {2016},
  pages        = {523--534},
  organization = {ACM},
}

@Article{zanjani2016,
  author    = {Zanjani, Motahareh Bahrami and Kagdi, Huzefa and Bird, Christian},
  title     = {Automatically recommending peer reviewers in modern code review},
  journal   = {IEEE Transactions on Software Engineering},
  year      = {2016},
  volume    = {42},
  number    = {6},
  pages     = {530--543},
  publisher = {IEEE},
}

@InProceedings{ying2016,
  author       = {Ying, Haochao and Chen, Liang and Liang, Tingting and Wu, Jian},
  title        = {EARec: leveraging expertise and authority for pull-request reviewer recommendation in GitHub},
  booktitle    = {Proceedings of the 3rd International Workshop on CrowdSourcing in Software Engineering},
  year         = {2016},
  pages        = {29--35},
  organization = {ACM},
}

@Article{yang2016,
  author    = {Yang, Xin and Yoshida, Norihiro and Kula, Raula Gaikovina and Iida, Hajimu},
  title     = {Peer review social network (PeRSoN) in open source projects},
  journal   = {IEICE TRANSACTIONS on Information and Systems},
  year      = {2016},
  volume    = {99},
  number    = {3},
  pages     = {661--670},
  publisher = {The Institute of Electronics, Information and Communication Engineers},
}

@InProceedings{xia2015,
  author       = {Xia, Xin and Lo, David and Wang, Xinyu and Yang, Xiaohu},
  title        = {Who should review this change?: Putting text and file location analyses together for more accurate recommendations},
  booktitle    = {Software Maintenance and Evolution (ICSME), 2015 IEEE International Conference on},
  year         = {2015},
  pages        = {261--270},
  organization = {IEEE},
}

@Article{jiang2015,
  author    = {Jiang, Jing and He, Jia-Huan and Chen, Xue-Yuan},
  title     = {Coredevrec: Automatic core member recommendation for contribution evaluation},
  journal   = {Journal of Computer Science and Technology},
  year      = {2015},
  volume    = {30},
  number    = {5},
  pages     = {998--1016},
  publisher = {Springer},
}

@Article{jiang2017,
  author    = {Jiang, Jing and Yang, Yun and He, Jiahuan and Blanc, Xavier and Zhang, Li},
  title     = {Who should comment on this pull request? Analyzing attributes for more accurate commenter recommendation in pull-based development},
  journal   = {Information and Software Technology},
  year      = {2017},
  volume    = {84},
  pages     = {48--62},
  publisher = {Elsevier},
}

@Article{schettino2014,
  author = {Schettino, Vinicius Junqueira and Araújo, Marco Antônio Pereira},
  title  = {Implantação da prática de code review em um modelo de desenvolvimento de software: um estudo de caso},
  year   = {2017},
}

@Article{barr2012,
  author    = {Barr, Earl and Bird, Christian and Rigby, Peter and Hindle, Abram and German, Daniel and Devanbu, Premkumar},
  title     = {Cohesive and isolated development with branches},
  journal   = {Fundamental Approaches to Software Engineering},
  year      = {2012},
  pages     = {316--331},
  publisher = {Springer},
}

@InProceedings{bauer2011,
  author    = {Bauer, Bela and Gukelberger, Jan and Surer, Brigitte and Troyer, Matthias},
  title     = {Publishing Provenance-rich Scientific Papers.},
  booktitle = {TaPP},
  year      = {2011},
}

@InProceedings{freire2012,
  author       = {Freire, Juliana and Bonnet, Philippe and Shasha, Dennis},
  title        = {Computational reproducibility: state-of-the-art, challenges, and database research opportunities},
  booktitle    = {Proceedings of the 2012 ACM SIGMOD international conference on management of data},
  year         = {2012},
  pages        = {593--596},
  organization = {ACM},
}

@Article{ince2012,
  author    = {Ince, Darrel C and Hatton, Leslie and Graham-Cumming, John},
  title     = {The case for open computer programs},
  journal   = {Nature},
  year      = {2012},
  volume    = {482},
  number    = {7386},
  pages     = {485--488},
  publisher = {Nature Research},
}

@Article{collberg2014,
  author  = {Collberg, Christian and Proebsting, Todd and Moraila, Gina and Shankaran, Akash and Shi, Zuoming and Warren, Alex M},
  title   = {Measuring reproducibility in computer systems research},
  journal = {Department of Computer Science, University of Arizona, Tech. Rep},
  year    = {2014},
}

@Article{garijo2013,
  author    = {Garijo, Daniel and Kinnings, Sarah and Xie, Li and Xie, Lei and Zhang, Yinliang and Bourne, Philip E and Gil, Yolanda},
  title     = {Quantifying reproducibility in computational biology: the case of the tuberculosis drugome},
  journal   = {PloS one},
  year      = {2013},
  volume    = {8},
  number    = {11},
  pages     = {e80278},
  publisher = {Public Library of Science},
}

@Article{gilbert2012,
  author    = {Gilbert, Kimberly J and Andrew, Rose L and Bock, Dan G and Franklin, Michelle T and Kane, Nolan C and Moore, Jean-S{\'e}bastien and Moyers, Brook T and Renaut, S{\'e}bastien and Rennison, Diana J and Veen, Thor and others},
  title     = {Recommendations for utilizing and reporting population genetic analyses: the reproducibility of genetic clustering using the program structure},
  journal   = {Molecular Ecology},
  year      = {2012},
  volume    = {21},
  number    = {20},
  pages     = {4925--4930},
  publisher = {Wiley Online Library},
}

@Article{boettiger2015,
  author    = {Boettiger, Carl},
  title     = {An introduction to Docker for reproducible research},
  journal   = {ACM SIGOPS Operating Systems Review},
  year      = {2015},
  volume    = {49},
  number    = {1},
  pages     = {71--79},
  publisher = {ACM},
}

@InProceedings{mazzara2005,
  author       = {Mazzara, Manuel and Govoni, Sergio},
  title        = {A case study of web services orchestration},
  booktitle    = {COORDINATION},
  year         = {2005},
  volume       = {5},
  pages        = {1--16},
  organization = {Springer},
}

@InCollection{dragoni2017,
  author    = {Dragoni, Nicola and Giallorenzo, Saverio and Lafuente, Alberto Lluch and Mazzara, Manuel and Montesi, Fabrizio and Mustafin, Ruslan and Safina, Larisa},
  title     = {Microservices: yesterday, today, and tomorrow},
  booktitle = {Present and Ulterior Software Engineering},
  publisher = {Springer},
  year      = {2017},
  pages     = {195--216},
}

@InProceedings{clark2014,
  author        = {Clark, Dav and Culich, Aaron and Hamlin, Brian and Lovett, Ryan},
  title         = {BCE: Berkeley’s common scientific compute environment for research and education},
  booktitle     = {Proceedings of the 13th Python in Science Conference (SciPy 2014)},
  year          = {2014},
  __markedentry = {[vschettino:1]},
}

@ARTICLE{guo2012,
author={P. Guo},
journal={Computing in Science Engineering},
title={CDE: A Tool for Creating Portable Experimental Software Packages},
year={2012},
volume={14},
number={4},
pages={32-35},
keywords={cloud computing;natural sciences computing;research and development;virtualisation;cloud computing;computational science;reproducible research;virtual appliances;virtualization;Computational modeling;Linux;Maintenance engineering;Reproducibility of results;Research and development;Scientific computing;Software engineering;Computational modeling;Linux;Maintenance engineering;Reproducibility of results;Research and development;Scientific computing;Software engineering;and enhancement;configuration management;distribution;maintenance;portability;scientific computing;software engineering;software release management and delivery},
doi={10.1109/MCSE.2012.36},
ISSN={1521-9615},
month={July},}
}

@InProceedings{chirigati2016,
  author       = {Chirigati, Fernando and Rampin, R{\'e}mi and Shasha, Dennis and Freire, Juliana},
  title        = {Reprozip: Computational reproducibility with ease},
  booktitle    = {Proceedings of the 2016 International Conference on Management of Data},
  year         = {2016},
  pages        = {2085--2088},
  organization = {ACM},
}

@Article{hutton2015,
  author    = {Hutton, Luke and Henderson, Tristan},
  title     = {Towards reproducibility in online social network research},
  journal   = {IEEE Transactions on Emerging Topics in Computing},
  year      = {2015},
  publisher = {IEEE},
}

@InProceedings{jurgens2015,
  author    = {Jurgens, David and Finethy, Tyler and Armstrong, Caitrin and Ruths, Derek},
  title     = {Everyone’s invited: A new paradigm for evaluation on non-transferable datasets},
  booktitle = {Ninth International AAAI Conference on Web and Social Media},
  year      = {2015},
}

@Article{guru2016,
  author    = {Guru, Siddeswara and Hanigan, Ivan C and Nguyen, Hoang Anh and Burns, Emma and Stein, John and Blanchard, Wade and Lindenmayer, David and Clancy, Tim},
  title     = {Development of a cloud-based platform for reproducible science: A case study of an IUCN Red List of Ecosystems Assessment},
  journal   = {Ecological Informatics},
  year      = {2016},
  volume    = {36},
  pages     = {221--230},
  publisher = {Elsevier},
}

@InProceedings{ramachandran2016,
  author       = {Ramachandran, Prabhu},
  title        = {Extensible, Reusable, and Reproducible Computing: A Case Study of PySPH},
  booktitle    = {Journal of Physics: Conference Series},
  year         = {2016},
  volume       = {759},
  number       = {1},
  pages        = {012094},
  organization = {IOP Publishing},
}

@InProceedings{gomes2012,
  author       = {Gomes, Gabriel FT and Borin, Edson},
  title        = {A Database for Reproducible Computational Research},
  booktitle    = {Computer Systems (WSCAD-SSC), 2012 13th Symposium on},
  year         = {2012},
  pages        = {141--147},
  organization = {IEEE},
}

@Article{ebert2015,
  author    = {Ebert, Peter and M{\"u}ller, Fabian and Nordstr{\"o}m, Karl and Lengauer, Thomas and Schulz, Marcel H},
  title     = {A general concept for consistent documentation of computational analyses},
  journal   = {Database},
  year      = {2015},
  volume    = {2015},
  publisher = {Oxford University Press},
}

@InProceedings{sinha2016,
  author       = {Sinha, Rajesh and Sudhish, Prem Sewak},
  title        = {A principled approach to reproducible research: a comparative review towards scientific integrity in computational research},
  booktitle    = {Ethics in Engineering, Science and Technology (ETHICS), 2016 IEEE International Symposium on},
  year         = {2016},
  pages        = {1--9},
  organization = {IEEE},
}

@inproceedings{russo2015,
  title={Advantages and Limits in the Adoption of Reproducible Research and R-Tools for the Analysis of Omic Data},
  author={Russo, Francesco and Righelli, Dario and Angelini, Claudia},
  booktitle={International Meeting on Computational Intelligence Methods for Bioinformatics and Biostatistics},
  pages={245--258},
  year={2015},
  organization={Springer}
}

@article{kreibig2017,
  title={Computational Reproducibility of" Goal Relevance and Goal Conduciveness Appraisals Lead to Differential Autonomic Reactivity in Emotional Responding to Performance Feedback"(Kreibig, Gendolla, \& Scherer, 2012): A Guide and New Evidence.},
  author={Kreibig, SD},
  journal={International journal of psychophysiology: official journal of the International Organization of Psychophysiology},
  year={2017}
}



@book{taylor2014,
 author = {Taylor, Ian J. and Deelman, Ewa and Gannon, Dennis B. and Shields, Matthew},
 title = {Workflows for e-Science: Scientific Workflows for Grids},
 year = {2014},
 isbn = {1849966192, 9781849966191},
 publisher = {Springer Publishing Company, Incorporated},
}

@inproceedings{altintas2004,
  title={Kepler: an extensible system for design and execution of scientific workflows},
  author={Altintas, Ilkay and Berkley, Chad and Jaeger, Efrat and Jones, Matthew and Ludascher, Bertram and Mock, Steve},
  booktitle={Scientific and Statistical Database Management, 2004. Proceedings. 16th International Conference on},
  pages={423--424},
  year={2004},
  organization={IEEE}
}

@article{merkel2014,
 author = {Merkel, Dirk},
 title = {Docker: Lightweight Linux Containers for Consistent Development and Deployment},
 journal = {Linux J.},
 issue_date = {March 2014},
 volume = {2014},
 number = {239},
 month = mar,
 year = {2014},
 issn = {1075-3583},
 articleno = {2},
 acmid = {2600241},
 publisher = {Belltown Media},
 address = {Houston, TX},
}

@article{bernstein2014,
  title={Containers and cloud: From lxc to docker to kubernetes},
  author={Bernstein, David},
  journal={IEEE Cloud Computing},
  volume={1},
  number={3},
  pages={81--84},
  year={2014},
  publisher={IEEE}
}

@article{von2006,
  title={The promise of research on open source software},
  author={Von Krogh, Georg and Von Hippel, Eric},
  journal={Management science},
  volume={52},
  number={7},
  pages={975--983},
  year={2006},
  publisher={INFORMS}
}

@InProceedings{bosu2015,
  author    = {Bosu, Amiangshu and Greiler, Michaela and Bird, Christian},
  title     = {Characteristics of Useful Code Reviews: An Empirical Study at Microsoft},
  booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
  year      = {2015},
  series    = {MSR '15},
  pages     = {146--156},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {2820538},
  isbn      = {978-0-7695-5594-2},
  location  = {Florence, Italy},
  numpages  = {11},
  url       = {http://dl.acm.org/citation.cfm?id=2820518.2820538},
}

@Article{yu2016,
  author     = {Yu, Yue and Wang, Huaimin and Yin, Gang and Wang, Tao},
  title      = {Reviewer Recommendation for Pull-requests in GitHub},
  journal    = {Inf. Softw. Technol.},
  year       = {2016},
  volume     = {74},
  number     = {C},
  pages      = {204--218},
  month      = jun,
  issn       = {0950-5849},
  acmid      = {2906305},
  address    = {Newton, MA, USA},
  doi        = {10.1016/j.infsof.2016.01.004},
  issue_date = {June 2016},
  keywords   = {Pull-request, Reviewer recommendation, Social network analysis},
  numpages   = {15},
  publisher  = {Butterworth-Heinemann},
  url        = {http://dx.doi.org/10.1016/j.infsof.2016.01.004},
}

@InProceedings{rahman2017,
  author    = {Rahman, Mohammad Masudur and Roy, Chanchal K. and Kula, Raula G.},
  title     = {Predicting Usefulness of Code Review Comments Using Textual Features and Developer Experience},
  booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
  year      = {2017},
  series    = {MSR '17},
  pages     = {215--226},
  address   = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  acmid     = {3104216},
  doi       = {10.1109/MSR.2017.17},
  isbn      = {978-1-5386-1544-7},
  keywords  = {change triggering capability, code element, code review quality, review comment usefulness, reviewing experience},
  location  = {Buenos Aires, Argentina},
  numpages  = {12},
  url       = {https://doi.org/10.1109/MSR.2017.17},
}

@InProceedings{yang2017,
  author    = {Yang, Cheng and Zhang, Xunhui and Zeng, Lingbin and Fan, Qiang and Yin, Gang and Wang, Huaimin},
  title     = {An Empirical Study of Reviewer Recommendation in Pull-based Development Model},
  booktitle = {Proceedings of the 9th Asia-Pacific Symposium on Internetware},
  year      = {2017},
  series    = {Internetware'17},
  pages     = {14:1--14:6},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3131718},
  articleno = {14},
  doi       = {10.1145/3131704.3131718},
  isbn      = {978-1-4503-5313-7},
  keywords  = {GitHub, code reviewer recommendation, pull request},
  location  = {Shanghai, China},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/3131704.3131718},
}

@Article{cosentino2017,
  author   = {V. Cosentino and J. L. Cánovas Izquierdo and J. Cabot},
  title    = {A Systematic Mapping Study of Software Development With GitHub},
  journal  = {IEEE Access},
  year     = {2017},
  volume   = {5},
  pages    = {7173-7192},
  issn     = {2169-3536},
  doi      = {10.1109/ACCESS.2017.2682323},
  keywords = {data mining;public domain software;social networking (online);software engineering;GitHub;coding-related tasks;distributed social coding platform;open source collaboration;open source repositories mining;project communities;sampling techniques;software development;software domain;software engineering;systematic mapping study;Collaboration;Conferences;Data mining;Libraries;Software;Software engineering;Systematics;GitHub;open source software;systematic mapping study},
}

@Comment{jabref-meta: databaseType:bibtex;}
